# ë©”ë‰´ì–¼ ê²€ìƒ‰ ê¸°ëŠ¥ (ì¤‘ê°„ ì„œë²„ ì—°ë™ ë°©ì‹ - Flask ê¸°ë°˜ ì„œë²„)

from flask import Flask, request, jsonify
from dotenv import load_dotenv
import os
import openai
from flask_cors import CORS
from pathlib import Path
from PyPDF2 import PdfReader
import chromadb
from chromadb.config import Settings
from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction

# ğŸ” í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# ğŸ§  Flask ì•± ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
app = Flask(__name__)
CORS(app)  # CORS ì„¤ì • ì¶”ê°€

# âœ… ë£¨íŠ¸ ê²½ë¡œ ìƒíƒœ í™•ì¸ìš©
@app.route("/", methods=["GET"])
def index():
    return "âœ… ì„œë²„ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.", 200

# ğŸ” POST ìš”ì²­ ì²˜ë¦¬ - GPTë¡œ ì§ˆë¬¸ ì „ë‹¬
@app.route("/search", methods=["POST"])
def search():
    question = request.json.get("question", "")

    messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ì²´ë¥˜/ì‚¬ì¦ ì „ë¬¸ GPT ë¹„ì„œì…ë‹ˆë‹¤. ë©”ë‰´ì–¼ì„ ê¸°ë°˜ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."},
        {"role": "user", "content": question}
    ]

    try:
        res = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            temperature=0.2
        )
        answer = res.choices[0].message.content
        return jsonify({"answer": answer})
    except Exception as e:
        return jsonify({"answer": f"GPT ì˜¤ë¥˜: {str(e)}"}), 500

# ğŸ“‚ ë©”ë‰´ì–¼ PDF ìë™ ì¸ì‹ (íŒŒì¼ëª… ê¸°ì¤€)
def get_manual_paths():
    base_dir = Path("C:/Users/ìœ¤ì°¬/ë‚´ ë“œë¼ì´ë¸Œ/í•œìš°ë¦¬ í˜„í–‰ì—…ë¬´/í”„ë¡œê·¸ë¨/ì¶œì…êµ­ì—…ë¬´ê´€ë¦¬/ë©”ë‰´ì–¼")
    stay_manuals = list(base_dir.glob("*ì²´ë¥˜ë¯¼ì›*.pdf"))
    visa_manuals = list(base_dir.glob("*ì‚¬ì¦ë¯¼ì›*.pdf"))
    print("ì²´ë¥˜ë¯¼ì› ë§¤ë‰´ì–¼ íŒŒì¼:", stay_manuals)
    print("ì‚¬ì¦ë¯¼ì› ë§¤ë‰´ì–¼ íŒŒì¼:", visa_manuals)
    return stay_manuals, visa_manuals

# ğŸ“š ë²¡í„° DB êµ¬ì¶• í•¨ìˆ˜ êµ¬í˜„

def build_vector_store(pdf_path, vector_store_path):
    print(f"[ë²¡í„° ìƒì„±] PDF: {pdf_path} â†’ ì €ì¥ ìœ„ì¹˜: {vector_store_path}")
    reader = PdfReader(pdf_path)
    text = "\n".join(page.extract_text() or "" for page in reader.pages)

    embedding_function = OpenAIEmbeddingFunction(api_key=openai.api_key)

    # âœ… ìµœì‹  ë°©ì‹ìœ¼ë¡œ ë³€ê²½
    client = chromadb.PersistentClient(path=vector_store_path)
    collection = client.get_or_create_collection(name="manual", embedding_function=embedding_function)

    chunks = [text[i:i+1000] for i in range(0, len(text), 1000)]
    metadatas = [{"source": str(pdf_path)}] * len(chunks)
    ids = [f"chunk_{i}" for i in range(len(chunks))]
    collection.add(documents=chunks, metadatas=metadatas, ids=ids)
    print("âœ… ë²¡í„° ì €ì¥ ì™„ë£Œ")

# ğŸ”¥ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
if __name__ == "__main__":
    stay_manuals, visa_manuals = get_manual_paths()
    for pdf in stay_manuals:
        build_vector_store(str(pdf), "vector_db/stay_manual")
    for pdf in visa_manuals:
        build_vector_store(str(pdf), "vector_db/visa_manual")
    app.run(host="0.0.0.0", port=10000, debug=True)
