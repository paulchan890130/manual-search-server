# ë©”ë‰´ì–¼ ê²€ìƒ‰ ê¸°ëŠ¥ (ì¤‘ê°„ ì„œë²„ ì—°ë™ ë°©ì‹ - Flask ê¸°ë°˜ ì„œë²„)

from flask import Flask, request, jsonify
from dotenv import load_dotenv
import os
import openai
from flask_cors import CORS

# ğŸ” í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# ğŸ§  Flask ì•± ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
app = Flask(__name__)
CORS(app)  # CORS ì„¤ì • ì¶”ê°€

# âœ… ë£¨íŠ¸ ê²½ë¡œ ìƒíƒœ í™•ì¸ìš©
@app.route("/", methods=["GET"])
def index():
    return "âœ… ì„œë²„ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.", 200

# ğŸ” POST ìš”ì²­ ì²˜ë¦¬ - GPTë¡œ ì§ˆë¬¸ ì „ë‹¬
@app.route("/search", methods=["POST"])
def search():
    question = request.json.get("question", "")

    messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ì²´ë¥˜/ì‚¬ì¦ ì „ë¬¸ GPT ë¹„ì„œì…ë‹ˆë‹¤. ë©”ë‰´ì–¼ì„ ê¸°ë°˜ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."},
        {"role": "user", "content": question}
    ]

    try:
        res = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            temperature=0.2
        )
        answer = res.choices[0].message.content
        return jsonify({"answer": answer})
    except Exception as e:
        return jsonify({"answer": f"GPT ì˜¤ë¥˜: {str(e)}"}), 500

# ğŸ“‚ ë©”ë‰´ì–¼ PDF ìë™ ì¸ì‹ (íŒŒì¼ëª… ê¸°ì¤€)
def get_manual_paths():
    base_dir = Path("C:/Users/ìœ¤ì°¬/ë‚´ ë“œë¼ì´ë¸Œ/í•œìš°ë¦¬ í˜„í–‰ì—…ë¬´/í”„ë¡œê·¸ë¨/ì¶œì…êµ­ì—…ë¬´ê´€ë¦¬/ë©”ë‰´ì–¼")
    stay_manuals = list(base_dir.glob("*ì²´ë¥˜ë¯¼ì›*.pdf"))
    visa_manuals = list(base_dir.glob("*ì‚¬ì¦ë¯¼ì›*.pdf"))
    print("ì²´ë¥˜ë¯¼ì› ë§¤ë‰´ì–¼ íŒŒì¼:", stay_manuals)
    print("ì‚¬ì¦ë¯¼ì› ë§¤ë‰´ì–¼ íŒŒì¼:", visa_manuals)
    return stay_manuals, visa_manuals

# ğŸ”¥ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=10000, debug=True)